{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Apriori on the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "# global frequency dictionary to store frequency of each row of dataset\n",
    "frequency = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join('.','7_Preprocess_Final.csv')\n",
    "df = pd.read_csv(filepath, usecols=[\"Season\", \"Crop\", \"Soil Type\", \"Rainfall_Disc\", \"Yield_Disc\"])\n",
    "df = df.reindex(columns=[\"Season\", \"Soil Type\", \"Rainfall_Disc\",\"Crop\", \"Yield_Disc\"])\n",
    "for j, col in enumerate(df.columns):\n",
    "    for i, val in enumerate(df[col]):\n",
    "        df.at[i, col] = str(j) + ' ' + col + ' = ' + val\n",
    "df.to_csv(r'AprioriInput.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    # reads the dataset and converts it into list of list\n",
    "    \n",
    "    df = pd.read_csv('AprioriInput.csv')\n",
    "    records = df.values.tolist()\n",
    "    for i in range(len(records)):\n",
    "        records[i] = frozenset(records[i])\n",
    "        if records[i] in frequency:\n",
    "            frequency[records[i]] += 1\n",
    "        else:\n",
    "            frequency[records[i]] = 1\n",
    "    return list(set(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createC1(dataSet):\n",
    "    # creates c1 that is candidate item set of size 1\n",
    "    \n",
    "    C1 = set()\n",
    "    for trans in dataSet:\n",
    "        for item in trans:\n",
    "            C1.add(frozenset([item]))\n",
    "    return list(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLK(DS, Ck, minSupport):\n",
    "    # creates Lk from Ck by removing those candidate sets\n",
    "    # which have support less than min support and returns\n",
    "    # Lk and a dictionary with support count\n",
    "    \n",
    "    sup_count = {}\n",
    "    for trans in DS:\n",
    "        for can in Ck:\n",
    "            if can.issubset(trans):\n",
    "                if can in sup_count:\n",
    "                    sup_count[can] += frequency[trans]\n",
    "                else:\n",
    "                    sup_count[can] = frequency[trans]\n",
    "    supportData = {}\n",
    "    Lk = []\n",
    "    for key in sup_count:\n",
    "        support = sup_count[key]\n",
    "        if support >= minSupport: # if it passes the min threshold\n",
    "            Lk.insert(0, key)     # insert it in Lk\n",
    "            supportData[key] = support\n",
    "    return Lk, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aprioriGen(Lkm1, k):\n",
    "    # returns Ck from Lk-1 by union of those frequent\n",
    "    # sets which have k-2 items equal\n",
    "\n",
    "    Ck = []\n",
    "    for i in range(len(Lkm1)):\n",
    "        for j in range(i+1, len(Lkm1)):\n",
    "            x = list(Lkm1[i])\n",
    "            y = list(Lkm1[j])\n",
    "            x.sort()\n",
    "            y.sort()\n",
    "            L1 = x[:k-2]\n",
    "            L2 = y[:k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            if L1 == L2:  # if first k-2 elements are equal\n",
    "                Ck.append(Lkm1[i] | Lkm1[j])  # set union\n",
    "    return Ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(dataSet, minSupport):\n",
    "    # returns a list of frequent itemsets and\n",
    "    # dictionary of support counts for those itemsets\n",
    "\n",
    "    C1 = createC1(dataSet)\n",
    "    L1, supportData = createLK(dataSet, C1, minSupport)\n",
    "    L = [L1]\n",
    "    k = 0\n",
    "    while (len(L[k]) > 0):\n",
    "        Ck = aprioriGen(L[k], k+2)\n",
    "        Lk, supK = createLK(dataSet, Ck, minSupport)\n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRules(itemsets, supportData, minConf):\n",
    "    # main rule gen function that generates and returns interesting\n",
    "    # association rules that passed the confidence threshold\n",
    "\n",
    "    Assoc_rules = {} # rules are stored in dictionary with antecedent as key and consequent and confidence as value\n",
    "    for itemset in itemsets:\n",
    "        sup_tot = supportData[frozenset(itemset)] # entire rule\n",
    "        ante = frozenset(itemset[:3]) # antecedent\n",
    "        sup_ante = supportData[ante]\n",
    "        conf = sup_tot/sup_ante # conf = sup(rule) / sup(antecedent)\n",
    "        if(conf >= minConf): # if confidence passes the min threshold add it to the rules\n",
    "            if ante in Assoc_rules:\n",
    "                Assoc_rules[ante].append([itemset[-2], itemset[-1], conf])\n",
    "            else :\n",
    "                Assoc_rules[ante] = [[itemset[-2], itemset[-1], conf]]\n",
    "    return Assoc_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and get the frequent itemset list by calling apriori function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "ds = loadDataSet() # load the dataset\n",
    "minsup = 50 # set the minimum support\n",
    "l, s = apriori(ds, minsup) # call apriori to get the frequent itemset and support count\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the item sets of size 5 and generate rules from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(l[4])): # l[4] has frequent itemsets of size 5 (0 indexed)\n",
    "    l[4][i] = list(l[4][i])\n",
    "    l[4][i].sort()\n",
    "minConf = 0 # set the minimum confidence\n",
    "rules = generateRules(l[4],s,minConf) # call generateRules to generate the rules\n",
    "print(len(rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take season, soil and rainfall as input from the user and\n",
    "output the crops with high yield using the above rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "5\n",
      "Rapeseed &Mustard\t\t4 Yield_Disc = Low\n",
      "Peas & beans (Pulses)\t\t4 Yield_Disc = Low\n",
      "Coriander\t\t4 Yield_Disc = Very_Low\n",
      "Onion\t\t4 Yield_Disc = Very_High\n",
      "Linseed\t\t4 Yield_Disc = Very_Low\n",
      "Rapeseed &Mustard\t\t4 Yield_Disc = Medium\n",
      "Potato\t\t4 Yield_Disc = Very_High\n",
      "Gram\t\t4 Yield_Disc = Low\n",
      "Wheat\t\t4 Yield_Disc = High\n",
      "Jowar\t\t4 Yield_Disc = Low\n",
      "Other  Rabi pulses\t\t4 Yield_Disc = Low\n",
      "Masoor\t\t4 Yield_Disc = Low\n",
      "Gram\t\t4 Yield_Disc = Very_Low\n",
      "Garlic\t\t4 Yield_Disc = Very_High\n",
      "Wheat\t\t4 Yield_Disc = Very_High\n"
     ]
    }
   ],
   "source": [
    "season = '0 Season = ' + ['Kharif','Summer','Whole Year','Rabi','Winter','Autumn'][int(input()) - 1]\n",
    "soil = '1 Soil Type = ' + ['Alluvial','Black','Red','Mountain','Laterite','Arid'][int(input()) - 1]\n",
    "rainfall = '2 Rainfall_Disc = ' + ['Very_High','High','Medium','Low','Very_Low'][int(input()) - 1]\n",
    "crops = rules[frozenset([season, soil, rainfall])]\n",
    "for crop in crops:\n",
    "    print(crop[0][9:], crop[1], sep = '\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
