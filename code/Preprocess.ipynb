{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of preprocessing: **Data Cleaning**. Missing values handled by ignoring some tuples and using mean to fill in the remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-072802664aa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m                         \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                         \u001b[0mco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                         \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'State_Name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Crop_Year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Season'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Rainfall'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\dm\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\dm\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\dm\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\dm\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"..\\\\data\\\\0_Final_Merged.csv\")\n",
    "\n",
    "# All tuples that have 0 in the production column are removed\n",
    "df = df[np.isfinite(df['Production'])]\n",
    "\n",
    "# All nan values filled with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "states = list(df.State_Name.unique())\n",
    "years = list(df.Crop_Year.unique())\n",
    "months = list(df.Season.unique())\n",
    "for month in months:\n",
    "\tdf.loc[df['Season'] == month, 'Season'] = month.strip() # Removing trailing spaces\n",
    "months = list(df.Season.unique())\n",
    "\n",
    "# Filling nan values of rainfall with mean value for a particular state, year and month\n",
    "for state in states:\n",
    "\tfor year in years:\n",
    "\t\tfor month in months:\n",
    "\t\t\tsm = 0\n",
    "\t\t\tco = 0\n",
    "\t\t\tnew_df = df[(df['State_Name'] == state) & (df['Crop_Year'] == year) & (df['Season'] == month)]\n",
    "\t\t\tfor column in new_df['Rainfall']:\n",
    "\t\t\t\tif column != 0:\n",
    "\t\t\t\t\tsm += column\n",
    "\t\t\t\t\tco -= -1\n",
    "\t\t\tav = 0\n",
    "\t\t\tif co != 0: av = sm / co\n",
    "\t\t\tdf.loc[((df['State_Name'] == state) & (df['Crop_Year'] == year) & (df['Season'] == month) & (df['Rainfall'] == 0)), 'Rainfall'] = av\n",
    "\n",
    "count = 0\n",
    "summ = 0\n",
    "for i in df['Rainfall']:\n",
    "\tif i != 0:\n",
    "\t\tsumm += i\n",
    "\t\tcount -= -1\n",
    "\n",
    "avg = summ / count\n",
    "\n",
    "df.loc[(df['Rainfall'] == 0), 'Rainfall'] = avg\n",
    "\n",
    "# Storing the output of the first step of data preprocessing to csv file\n",
    "df.to_csv('..\\\\data\\\\1_Preprocess_Data_Cleaning.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Reduction**: Stratified Sampling used for Numerosity Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\\\data\\\\1_Preprocess_Data_Cleaning.csv\")\n",
    "\n",
    "# Storing distinct column names\n",
    "column = list(df)\n",
    "\n",
    "# Creating a new dataframe that will be the output dataframe after nuerosity reduction\n",
    "my_df = pd.DataFrame(columns = column)\n",
    "\n",
    "# Storing unique Crop names\n",
    "crops = list(df.Crop.unique())\n",
    "\n",
    "# Stratified Sampling based on distinct crop names\n",
    "for crop in crops:\n",
    "\tnew_df = df[(df['Crop'] == crop)]\n",
    "\tnew_df = new_df.sample(frac = 0.7)\n",
    "\tmy_df = my_df.append(new_df, ignore_index = True)\n",
    "\n",
    "# Shuffling the dataframe to ensure randomness\n",
    "my_df = my_df.sample(frac = 1)\n",
    "\n",
    "# Storing the output in csv file\n",
    "my_df.to_csv('..\\\\data\\\\2_Preprocess_Numerosity_Reduction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Construction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\\\data\\\\2_Preprocess_Numerosity_Reduction.csv\")\n",
    "\n",
    "productions = []\n",
    "area = []\n",
    "\n",
    "for i in df['Production']: productions.append(i)\n",
    "\n",
    "for i in df['Area']: area.append(i)\n",
    "\n",
    "# Creating a new feature that will be used for all the further analysis\n",
    "yields = []\n",
    "\n",
    "for i in range(169655):\n",
    "\tyields.append(productions[i] / area[i])\n",
    "\n",
    "df['Yield'] = yields\n",
    "\n",
    "# Storing the output in csv file\n",
    "df.to_csv('..\\\\data\\\\3_Preprocess_Feature_Construction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization**: Z-Score normalisation used to normalise 'Rainfall' and 'Yield'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\\\data\\\\3_Preprocess_Feature_Construction.csv\")\n",
    "\n",
    "# Normalizing Rainfall using Z-Score\n",
    "rainfall_mean = df['Rainfall'].mean()\n",
    "rainfall_std = df['Rainfall'].std(ddof = 0)\n",
    "rainfall = []\n",
    "for i in df['Rainfall']: rainfall.append(i)\n",
    "for i in range(169655): rainfall[i] = (rainfall[i] - rainfall_mean) / rainfall_std\n",
    "df['Rainfall_ZScore'] = rainfall\n",
    "\n",
    "# Normalizing Yield using Z-Score\n",
    "yield_mean = df['Yield'].mean()\n",
    "yield_std = df['Yield'].std(ddof = 0)\n",
    "yields = []\n",
    "for i in df['Yield']: yields.append(i)\n",
    "for i in range(169655): yields[i] = (yields[i] - yield_mean) / yield_std\n",
    "df['Yield_ZScore'] = yields\n",
    "\n",
    "# Storing the output in csv file\n",
    "df.to_csv('..\\\\data\\\\4_Preprocess_Normalization_Z_Score.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discretization**: 'Rainfall' and 'Yield' are discretized into five categories - _very low, low, medium, high, very_high_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\\\data\\\\4_Preprocess_Normalization_Z_Score.csv\")\n",
    "\n",
    "# Different categories for discretizing\n",
    "classes = ['Very_Low', 'Low', 'Medium', 'High', 'Very_High']\n",
    "\n",
    "# Discretizing Rainfall\n",
    "rainfall_z = []\n",
    "for i in df['Rainfall_ZScore']: rainfall_z.append(i)\n",
    "minrain = min(rainfall_z)\n",
    "maxrain = max(rainfall_z)\n",
    "count = [0] * 5\n",
    "for i in range(169655):\n",
    "\tif rainfall_z[i] < -1.22:\n",
    "\t\ttemp = 0\n",
    "\telif rainfall_z[i] < -0.5:\n",
    "\t\ttemp = 1\n",
    "\telif rainfall_z[i] < 0.5:\n",
    "\t\ttemp = 2\n",
    "\telif rainfall_z[i] < 2.5:\n",
    "\t\ttemp = 3\n",
    "\telse:\n",
    "\t\ttemp = 4\n",
    "\tcount[temp] -= -1\n",
    "\trainfall_z[i] = classes[temp]\n",
    "\n",
    "# Discretizing Yield\n",
    "yield_z = []\n",
    "for i in df['Yield_ZScore']: yield_z.append(i)\n",
    "minyield = min(yield_z)\n",
    "maxyield = max(yield_z)\n",
    "delta = (-0.047 - minyield) / 5\n",
    "count = [0] * 5\n",
    "for i in range(169655):\n",
    "\ttemp = int((yield_z[i] - minyield) // delta)\n",
    "\tif temp > 4: temp = 4\n",
    "\tcount[temp] -= -1\n",
    "\tyield_z[i] = classes[temp]\n",
    "\n",
    "df['Rainfall_Disc'] = rainfall_z\n",
    "df['Yield_Disc'] = yield_z\n",
    "\n",
    "# Storing the output in csv file\n",
    "df.to_csv('..\\\\data\\\\5_Preprocess_Discretization.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binarization**: Discretized 'Rainfall' and 'Yield' are mapped to five binary variables corresponding to five categories. A binary variable represents the presence or absence of a record in that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('..\\\\data\\\\5_Preprocess_Discretization.csv')\n",
    "\n",
    "rainfall = []\n",
    "\n",
    "# Each bit represents a category for rainfall\n",
    "for i in df['Rainfall_Disc']:\n",
    "\tif i == 'Very_Low': rainfall.append([1, 0, 0, 0, 0])\n",
    "\telif i == 'Low': rainfall.append([0, 1, 0, 0, 0])\n",
    "\telif i == 'Medium': rainfall.append([0, 0, 1, 0, 0])\n",
    "\telif i == 'High': rainfall.append([0, 0, 0, 1, 0])\n",
    "\telse: rainfall.append([0, 0, 0, 0, 1])\n",
    "\n",
    "# Five categories of rainfall\n",
    "rainfall_vl = []\n",
    "rainfall_l = []\n",
    "rainfall_m = []\n",
    "rainfall_h = []\n",
    "rainfall_vh = []\n",
    "\n",
    "for i in range(169655):\n",
    "\trainfall_vl.append(rainfall[i][0])\n",
    "\trainfall_l.append(rainfall[i][1])\n",
    "\trainfall_m.append(rainfall[i][2])\n",
    "\trainfall_h.append(rainfall[i][3])\n",
    "\trainfall_vh.append(rainfall[i][4])\n",
    "\n",
    "df['Rainfall_Very_Low'] = rainfall_vl\n",
    "df['Rainfall_Low'] = rainfall_l\n",
    "df['Rainfall_Medium'] = rainfall_m\n",
    "df['Rainfall_High'] = rainfall_h\n",
    "df['Rainfall_Very_High'] = rainfall_vh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "yields = []\n",
    "\n",
    "# Each bit represents a category for yield\n",
    "for i in df['Yield_Disc']:\n",
    "\tif i == 'Very_Low': yields.append([1, 0, 0, 0, 0])\n",
    "\telif i == 'Low': yields.append([0, 1, 0, 0, 0])\n",
    "\telif i == 'Medium': yields.append([0, 0, 1, 0, 0])\n",
    "\telif i == 'High': yields.append([0, 0, 0, 1, 0])\n",
    "\telse: yields.append([0, 0, 0, 0, 1])\n",
    "\n",
    "# Five categories of yield\n",
    "yield_vl = []\n",
    "yield_l = []\n",
    "yield_m = []\n",
    "yield_h = []\n",
    "yield_vh = []\n",
    "\n",
    "for i in range(169655):\n",
    "\tyield_vl.append(yields[i][0])\n",
    "\tyield_l.append(yields[i][1])\n",
    "\tyield_m.append(yields[i][2])\n",
    "\tyield_h.append(yields[i][3])\n",
    "\tyield_vh.append(yields[i][4])\n",
    "\n",
    "df['Yield_Very_Low'] = yield_vl\n",
    "df['Yield_Low'] = yield_l\n",
    "df['Yield_Medium'] = yield_m\n",
    "df['Yield_High'] = yield_h\n",
    "df['Yield_Very_High'] = yield_vh\n",
    "\n",
    "# Storing the output in csv file\n",
    "df.to_csv('..\\\\data\\\\6_Preprocess_Binarization.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Preprocessed Data**: All the columns that are not important for our further analysis (Association Rule Mining, Clustering and Classification) are now removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['State_Name', 'District_Name', 'Crop_Year', 'Area', 'Production', 'Rainfall', 'Yield', 'Rainfall_ZScore', 'Yield_ZScore'], axis = 1)\n",
    "df.to_csv('..\\\\data\\\\7_Preprocess_Final.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
